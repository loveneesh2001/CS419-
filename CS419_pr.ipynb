{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS419_pr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmStrmWAeSzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1517107-e337-4790-d779-eabceb8fd083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/creditcard.csv')"
      ],
      "metadata": {
        "id": "FAOK7q5_fZxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tdsjZFtLXon",
        "outputId": "a9e718f2-16d9-4092-cf71-6b3217508b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "rDcJRb6HgDUW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "47e9ec55-6b55-4bc2-ba86-ebc618090044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7676900f-399b-46ff-81b5-6638dd41a7e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7676900f-399b-46ff-81b5-6638dd41a7e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7676900f-399b-46ff-81b5-6638dd41a7e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7676900f-399b-46ff-81b5-6638dd41a7e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "YwZ0EWRyi2ID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "fd0fd3b8-8a78-41c6-bbac-6118616b0f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df3189a3-d311-487a-b1d6-04403a359f15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df3189a3-d311-487a-b1d6-04403a359f15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df3189a3-d311-487a-b1d6-04403a359f15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df3189a3-d311-487a-b1d6-04403a359f15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here \n",
        "0-> Legit Transaction\n",
        "1-> Fraud Transaction"
      ],
      "metadata": {
        "id": "i13XoIoni7aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape                                                    "
      ],
      "metadata": {
        "id": "J5HEGKRGgUKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4089c68b-933b-4024-dde8-aa1484697d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the distribution of Legit and Fraud transactions."
      ],
      "metadata": {
        "id": "uQ9i0k5pggki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Class'].value_counts()"
      ],
      "metadata": {
        "id": "EHEPNrCigwCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb58f559-a395-4c04-a79f-13741100cf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data is highly unbalanced as it reports more than 99 percent of times as legit transaction. So, we cannot feed this directly into our model."
      ],
      "metadata": {
        "id": "EfC97hPzjpxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the number of missing values in each column\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "i4rmbsq6jlc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10b40f4-0d9c-416c-b538-4ac64dfc07ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separating the data\n",
        "\n",
        "legit = data[data.Class == 0]\n",
        "fraud = data[data.Class == 1]"
      ],
      "metadata": {
        "id": "xCGysFA8lLbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(legit.shape)\n",
        "print(fraud.shape)"
      ],
      "metadata": {
        "id": "70YnaUDZlu71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4e9303-b575-4916-cb0f-7b696c773a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(284315, 31)\n",
            "(492, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under-Sampling\n",
        "Making the number of legit and fraud transactions equal\n",
        "\n",
        "Number of Fraud -> 492"
      ],
      "metadata": {
        "id": "IWDBO3T1tdLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "legit_n = legit.sample(n=492) #Taking out 492 samples"
      ],
      "metadata": {
        "id": "JcOZcU1PtTM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging the new legit and fraud samples"
      ],
      "metadata": {
        "id": "Oie7xlFbuE4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_n = pd.concat([legit_n, fraud], axis = 0)"
      ],
      "metadata": {
        "id": "NimiaTAJuDdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_n.head()"
      ],
      "metadata": {
        "id": "qfaw8GmtuboM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a7f67266-a828-47aa-ca6f-23badecee4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "117088   74534.0 -0.357993  1.077766  1.289151  0.072752  0.020203 -1.013877   \n",
              "124324   77256.0  1.238656 -1.417302 -0.008874 -1.273330 -1.605464 -1.022292   \n",
              "177812  123355.0 -0.264157  0.778577  0.232458 -0.920576  0.611408 -0.650198   \n",
              "76528    56613.0 -0.326433 -0.391379  1.546473 -1.631700 -0.395855  0.158239   \n",
              "71774    54438.0  1.221766 -0.152029  0.718813  0.123456 -0.950473 -0.940924   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "117088  0.660614 -0.047138 -0.329995  ... -0.267096 -0.724364 -0.008026   \n",
              "124324 -0.656401 -0.162963 -2.098971  ... -0.082218 -0.246941 -0.108679   \n",
              "177812  1.127008 -0.325278  0.752992  ... -0.421819 -0.704049 -0.006149   \n",
              "76528  -0.489154  0.032492 -2.701945  ... -0.156880 -0.083741 -0.238018   \n",
              "71774  -0.312783 -0.080173  0.512534  ... -0.191593 -0.652588  0.146456   \n",
              "\n",
              "             V24       V25       V26       V27       V28  Amount  Class  \n",
              "117088  0.323052 -0.174030  0.073287  0.242486  0.097849    1.78      0  \n",
              "124324  0.483885  0.399172 -0.182942 -0.029433  0.022668  141.70      0  \n",
              "177812 -0.414659 -0.504562  0.100977  0.109233 -0.233148    8.94      0  \n",
              "76528  -0.772175  0.242858  0.055264  0.104202  0.070786   20.00      0  \n",
              "71774   0.389713 -0.026378  0.789799 -0.071779  0.016492   25.80      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0fd5ce7-9617-4dcb-98d3-224fa0cc1e23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>117088</th>\n",
              "      <td>74534.0</td>\n",
              "      <td>-0.357993</td>\n",
              "      <td>1.077766</td>\n",
              "      <td>1.289151</td>\n",
              "      <td>0.072752</td>\n",
              "      <td>0.020203</td>\n",
              "      <td>-1.013877</td>\n",
              "      <td>0.660614</td>\n",
              "      <td>-0.047138</td>\n",
              "      <td>-0.329995</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.267096</td>\n",
              "      <td>-0.724364</td>\n",
              "      <td>-0.008026</td>\n",
              "      <td>0.323052</td>\n",
              "      <td>-0.174030</td>\n",
              "      <td>0.073287</td>\n",
              "      <td>0.242486</td>\n",
              "      <td>0.097849</td>\n",
              "      <td>1.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124324</th>\n",
              "      <td>77256.0</td>\n",
              "      <td>1.238656</td>\n",
              "      <td>-1.417302</td>\n",
              "      <td>-0.008874</td>\n",
              "      <td>-1.273330</td>\n",
              "      <td>-1.605464</td>\n",
              "      <td>-1.022292</td>\n",
              "      <td>-0.656401</td>\n",
              "      <td>-0.162963</td>\n",
              "      <td>-2.098971</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082218</td>\n",
              "      <td>-0.246941</td>\n",
              "      <td>-0.108679</td>\n",
              "      <td>0.483885</td>\n",
              "      <td>0.399172</td>\n",
              "      <td>-0.182942</td>\n",
              "      <td>-0.029433</td>\n",
              "      <td>0.022668</td>\n",
              "      <td>141.70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177812</th>\n",
              "      <td>123355.0</td>\n",
              "      <td>-0.264157</td>\n",
              "      <td>0.778577</td>\n",
              "      <td>0.232458</td>\n",
              "      <td>-0.920576</td>\n",
              "      <td>0.611408</td>\n",
              "      <td>-0.650198</td>\n",
              "      <td>1.127008</td>\n",
              "      <td>-0.325278</td>\n",
              "      <td>0.752992</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.421819</td>\n",
              "      <td>-0.704049</td>\n",
              "      <td>-0.006149</td>\n",
              "      <td>-0.414659</td>\n",
              "      <td>-0.504562</td>\n",
              "      <td>0.100977</td>\n",
              "      <td>0.109233</td>\n",
              "      <td>-0.233148</td>\n",
              "      <td>8.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76528</th>\n",
              "      <td>56613.0</td>\n",
              "      <td>-0.326433</td>\n",
              "      <td>-0.391379</td>\n",
              "      <td>1.546473</td>\n",
              "      <td>-1.631700</td>\n",
              "      <td>-0.395855</td>\n",
              "      <td>0.158239</td>\n",
              "      <td>-0.489154</td>\n",
              "      <td>0.032492</td>\n",
              "      <td>-2.701945</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.156880</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.238018</td>\n",
              "      <td>-0.772175</td>\n",
              "      <td>0.242858</td>\n",
              "      <td>0.055264</td>\n",
              "      <td>0.104202</td>\n",
              "      <td>0.070786</td>\n",
              "      <td>20.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71774</th>\n",
              "      <td>54438.0</td>\n",
              "      <td>1.221766</td>\n",
              "      <td>-0.152029</td>\n",
              "      <td>0.718813</td>\n",
              "      <td>0.123456</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.940924</td>\n",
              "      <td>-0.312783</td>\n",
              "      <td>-0.080173</td>\n",
              "      <td>0.512534</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.191593</td>\n",
              "      <td>-0.652588</td>\n",
              "      <td>0.146456</td>\n",
              "      <td>0.389713</td>\n",
              "      <td>-0.026378</td>\n",
              "      <td>0.789799</td>\n",
              "      <td>-0.071779</td>\n",
              "      <td>0.016492</td>\n",
              "      <td>25.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0fd5ce7-9617-4dcb-98d3-224fa0cc1e23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0fd5ce7-9617-4dcb-98d3-224fa0cc1e23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0fd5ce7-9617-4dcb-98d3-224fa0cc1e23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_n.tail()"
      ],
      "metadata": {
        "id": "S_6OGMK7ukEa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "3071fee6-869b-476c-d992-602abf4cc266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
              "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
              "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
              "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
              "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "279863 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
              "280143 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
              "280149 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
              "281144 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
              "281674  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
              "\n",
              "             V24       V25       V26       V27       V28  Amount  Class  \n",
              "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
              "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
              "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
              "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
              "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9915cd55-dd85-4214-b78d-d21f0829cb25\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>279863</th>\n",
              "      <td>169142.0</td>\n",
              "      <td>-1.927883</td>\n",
              "      <td>1.125653</td>\n",
              "      <td>-4.518331</td>\n",
              "      <td>1.749293</td>\n",
              "      <td>-1.566487</td>\n",
              "      <td>-2.010494</td>\n",
              "      <td>-0.882850</td>\n",
              "      <td>0.697211</td>\n",
              "      <td>-2.064945</td>\n",
              "      <td>...</td>\n",
              "      <td>0.778584</td>\n",
              "      <td>-0.319189</td>\n",
              "      <td>0.639419</td>\n",
              "      <td>-0.294885</td>\n",
              "      <td>0.537503</td>\n",
              "      <td>0.788395</td>\n",
              "      <td>0.292680</td>\n",
              "      <td>0.147968</td>\n",
              "      <td>390.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280143</th>\n",
              "      <td>169347.0</td>\n",
              "      <td>1.378559</td>\n",
              "      <td>1.289381</td>\n",
              "      <td>-5.004247</td>\n",
              "      <td>1.411850</td>\n",
              "      <td>0.442581</td>\n",
              "      <td>-1.326536</td>\n",
              "      <td>-1.413170</td>\n",
              "      <td>0.248525</td>\n",
              "      <td>-1.127396</td>\n",
              "      <td>...</td>\n",
              "      <td>0.370612</td>\n",
              "      <td>0.028234</td>\n",
              "      <td>-0.145640</td>\n",
              "      <td>-0.081049</td>\n",
              "      <td>0.521875</td>\n",
              "      <td>0.739467</td>\n",
              "      <td>0.389152</td>\n",
              "      <td>0.186637</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280149</th>\n",
              "      <td>169351.0</td>\n",
              "      <td>-0.676143</td>\n",
              "      <td>1.126366</td>\n",
              "      <td>-2.213700</td>\n",
              "      <td>0.468308</td>\n",
              "      <td>-1.120541</td>\n",
              "      <td>-0.003346</td>\n",
              "      <td>-2.234739</td>\n",
              "      <td>1.210158</td>\n",
              "      <td>-0.652250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.751826</td>\n",
              "      <td>0.834108</td>\n",
              "      <td>0.190944</td>\n",
              "      <td>0.032070</td>\n",
              "      <td>-0.739695</td>\n",
              "      <td>0.471111</td>\n",
              "      <td>0.385107</td>\n",
              "      <td>0.194361</td>\n",
              "      <td>77.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281144</th>\n",
              "      <td>169966.0</td>\n",
              "      <td>-3.113832</td>\n",
              "      <td>0.585864</td>\n",
              "      <td>-5.399730</td>\n",
              "      <td>1.817092</td>\n",
              "      <td>-0.840618</td>\n",
              "      <td>-2.943548</td>\n",
              "      <td>-2.208002</td>\n",
              "      <td>1.058733</td>\n",
              "      <td>-1.632333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.583276</td>\n",
              "      <td>-0.269209</td>\n",
              "      <td>-0.456108</td>\n",
              "      <td>-0.183659</td>\n",
              "      <td>-0.328168</td>\n",
              "      <td>0.606116</td>\n",
              "      <td>0.884876</td>\n",
              "      <td>-0.253700</td>\n",
              "      <td>245.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281674</th>\n",
              "      <td>170348.0</td>\n",
              "      <td>1.991976</td>\n",
              "      <td>0.158476</td>\n",
              "      <td>-2.583441</td>\n",
              "      <td>0.408670</td>\n",
              "      <td>1.151147</td>\n",
              "      <td>-0.096695</td>\n",
              "      <td>0.223050</td>\n",
              "      <td>-0.068384</td>\n",
              "      <td>0.577829</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.164350</td>\n",
              "      <td>-0.295135</td>\n",
              "      <td>-0.072173</td>\n",
              "      <td>-0.450261</td>\n",
              "      <td>0.313267</td>\n",
              "      <td>-0.289617</td>\n",
              "      <td>0.002988</td>\n",
              "      <td>-0.015309</td>\n",
              "      <td>42.53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9915cd55-dd85-4214-b78d-d21f0829cb25')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9915cd55-dd85-4214-b78d-d21f0829cb25 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9915cd55-dd85-4214-b78d-d21f0829cb25');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_n['Class'].value_counts()"
      ],
      "metadata": {
        "id": "fhNzsinVuojd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6893a0e7-1ecb-46bb-8edb-f1713a2fc530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    492\n",
              "1    492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting Up into feature and target variable\n",
        "Y = data_n['Class']\n",
        "X = data_n.drop(columns='Class', axis=1)\n"
      ],
      "metadata": {
        "id": "cVHiV0oAu5WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y.head()"
      ],
      "metadata": {
        "id": "YRJ9GsG7QQWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83630a2-8ebf-47f2-a391-2937e5b54258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117088    0\n",
              "124324    0\n",
              "177812    0\n",
              "76528     0\n",
              "71774     0\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "TTaFwwmQvOdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8ee38888-435c-4fbf-fcf4-0e0b4ef6fdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "117088   74534.0 -0.357993  1.077766  1.289151  0.072752  0.020203 -1.013877   \n",
              "124324   77256.0  1.238656 -1.417302 -0.008874 -1.273330 -1.605464 -1.022292   \n",
              "177812  123355.0 -0.264157  0.778577  0.232458 -0.920576  0.611408 -0.650198   \n",
              "76528    56613.0 -0.326433 -0.391379  1.546473 -1.631700 -0.395855  0.158239   \n",
              "71774    54438.0  1.221766 -0.152029  0.718813  0.123456 -0.950473 -0.940924   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "117088  0.660614 -0.047138 -0.329995  ...  0.091270 -0.267096 -0.724364   \n",
              "124324 -0.656401 -0.162963 -2.098971  ... -0.181831 -0.082218 -0.246941   \n",
              "177812  1.127008 -0.325278  0.752992  ...  0.228654 -0.421819 -0.704049   \n",
              "76528  -0.489154  0.032492 -2.701945  ... -0.014156 -0.156880 -0.083741   \n",
              "71774  -0.312783 -0.080173  0.512534  ... -0.073032 -0.191593 -0.652588   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \n",
              "117088 -0.008026  0.323052 -0.174030  0.073287  0.242486  0.097849    1.78  \n",
              "124324 -0.108679  0.483885  0.399172 -0.182942 -0.029433  0.022668  141.70  \n",
              "177812 -0.006149 -0.414659 -0.504562  0.100977  0.109233 -0.233148    8.94  \n",
              "76528  -0.238018 -0.772175  0.242858  0.055264  0.104202  0.070786   20.00  \n",
              "71774   0.146456  0.389713 -0.026378  0.789799 -0.071779  0.016492   25.80  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50ac26cb-e015-4d39-bb10-13d54b880489\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>117088</th>\n",
              "      <td>74534.0</td>\n",
              "      <td>-0.357993</td>\n",
              "      <td>1.077766</td>\n",
              "      <td>1.289151</td>\n",
              "      <td>0.072752</td>\n",
              "      <td>0.020203</td>\n",
              "      <td>-1.013877</td>\n",
              "      <td>0.660614</td>\n",
              "      <td>-0.047138</td>\n",
              "      <td>-0.329995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091270</td>\n",
              "      <td>-0.267096</td>\n",
              "      <td>-0.724364</td>\n",
              "      <td>-0.008026</td>\n",
              "      <td>0.323052</td>\n",
              "      <td>-0.174030</td>\n",
              "      <td>0.073287</td>\n",
              "      <td>0.242486</td>\n",
              "      <td>0.097849</td>\n",
              "      <td>1.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124324</th>\n",
              "      <td>77256.0</td>\n",
              "      <td>1.238656</td>\n",
              "      <td>-1.417302</td>\n",
              "      <td>-0.008874</td>\n",
              "      <td>-1.273330</td>\n",
              "      <td>-1.605464</td>\n",
              "      <td>-1.022292</td>\n",
              "      <td>-0.656401</td>\n",
              "      <td>-0.162963</td>\n",
              "      <td>-2.098971</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.181831</td>\n",
              "      <td>-0.082218</td>\n",
              "      <td>-0.246941</td>\n",
              "      <td>-0.108679</td>\n",
              "      <td>0.483885</td>\n",
              "      <td>0.399172</td>\n",
              "      <td>-0.182942</td>\n",
              "      <td>-0.029433</td>\n",
              "      <td>0.022668</td>\n",
              "      <td>141.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177812</th>\n",
              "      <td>123355.0</td>\n",
              "      <td>-0.264157</td>\n",
              "      <td>0.778577</td>\n",
              "      <td>0.232458</td>\n",
              "      <td>-0.920576</td>\n",
              "      <td>0.611408</td>\n",
              "      <td>-0.650198</td>\n",
              "      <td>1.127008</td>\n",
              "      <td>-0.325278</td>\n",
              "      <td>0.752992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.228654</td>\n",
              "      <td>-0.421819</td>\n",
              "      <td>-0.704049</td>\n",
              "      <td>-0.006149</td>\n",
              "      <td>-0.414659</td>\n",
              "      <td>-0.504562</td>\n",
              "      <td>0.100977</td>\n",
              "      <td>0.109233</td>\n",
              "      <td>-0.233148</td>\n",
              "      <td>8.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76528</th>\n",
              "      <td>56613.0</td>\n",
              "      <td>-0.326433</td>\n",
              "      <td>-0.391379</td>\n",
              "      <td>1.546473</td>\n",
              "      <td>-1.631700</td>\n",
              "      <td>-0.395855</td>\n",
              "      <td>0.158239</td>\n",
              "      <td>-0.489154</td>\n",
              "      <td>0.032492</td>\n",
              "      <td>-2.701945</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.014156</td>\n",
              "      <td>-0.156880</td>\n",
              "      <td>-0.083741</td>\n",
              "      <td>-0.238018</td>\n",
              "      <td>-0.772175</td>\n",
              "      <td>0.242858</td>\n",
              "      <td>0.055264</td>\n",
              "      <td>0.104202</td>\n",
              "      <td>0.070786</td>\n",
              "      <td>20.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71774</th>\n",
              "      <td>54438.0</td>\n",
              "      <td>1.221766</td>\n",
              "      <td>-0.152029</td>\n",
              "      <td>0.718813</td>\n",
              "      <td>0.123456</td>\n",
              "      <td>-0.950473</td>\n",
              "      <td>-0.940924</td>\n",
              "      <td>-0.312783</td>\n",
              "      <td>-0.080173</td>\n",
              "      <td>0.512534</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073032</td>\n",
              "      <td>-0.191593</td>\n",
              "      <td>-0.652588</td>\n",
              "      <td>0.146456</td>\n",
              "      <td>0.389713</td>\n",
              "      <td>-0.026378</td>\n",
              "      <td>0.789799</td>\n",
              "      <td>-0.071779</td>\n",
              "      <td>0.016492</td>\n",
              "      <td>25.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50ac26cb-e015-4d39-bb10-13d54b880489')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50ac26cb-e015-4d39-bb10-13d54b880489 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50ac26cb-e015-4d39-bb10-13d54b880489');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting into training and testing data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "X_train=np.array(X_train)\n",
        "Y_train=np.array(Y_train)\n",
        "X_test=np.array(X_test)\n",
        "Y_test=np.array(Y_test)"
      ],
      "metadata": {
        "id": "DzRA93_ova9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape, Y_train.shape)"
      ],
      "metadata": {
        "id": "OJTcZNWkvokR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45beb60f-827c-456f-e4a8-36dba1d82212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(984, 30) (787, 30) (197, 30) (787,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "gTKaNgjsv5sQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "s9Wlp9E4wAYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train : \", X_train.shape)\n",
        "print(\"Shape of Y_train : \", Y_train.shape)\n",
        "print(\"Shape of X_test : \", X_test.shape)\n",
        "print(\"Shape of Y_test : \", Y_test.shape)"
      ],
      "metadata": {
        "id": "Qk2owhzw2IO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54da32c-e3d1-4d06-f531-bb5bb46518ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train :  (787, 30)\n",
            "Shape of Y_train :  (787,)\n",
            "Shape of X_test :  (197, 30)\n",
            "Shape of Y_test :  (197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradients(X, y, y_hat):\n",
        "    \n",
        "    # X --> Input.\n",
        "    # y --> true/target value.\n",
        "    # y_hat --> hypothesis/predictions.\n",
        "    # w --> weights (parameter).\n",
        "    # b --> bias (parameter).\n",
        "    \n",
        "    # m-> number of training examples.\n",
        "    m = X.shape[0]\n",
        "    \n",
        "    # Gradient of loss w.r.t weights.\n",
        "    dw = (1/m)*np.dot(X.T, (y_hat - y))\n",
        "    \n",
        "    # Gradient of loss w.r.t bias.\n",
        "    db = (1/m)*np.sum((y_hat - y)) \n",
        "    \n",
        "    return dw, db\n",
        "    "
      ],
      "metadata": {
        "id": "GV7RTjz7T4mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(X, Y, W, B):\n",
        "    \n",
        "    Z = np.dot(W.T, X) + B\n",
        "    A = sigmoid(Z)\n",
        "    \n",
        "    A = A > 0.5\n",
        "    \n",
        "    A = np.array(A, dtype = 'int64')\n",
        "    \n",
        "    acc = (1 - np.sum(np.absolute(A - Y))/Y.shape[1])*100\n",
        "    \n",
        "    print(\"Accuracy of the model is : \", round(acc, 2), \"%\")"
      ],
      "metadata": {
        "id": "vSlYilUkK934"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y, y_hat):\n",
        "    loss = -np.mean(y*(np.log(y_hat+1e-5)) - (1-y)*np.log(1-y_hat+1e-5))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "2Vz_6yEdUBhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For nomalizing the X values\n",
        "\n",
        "def normalize(X):\n",
        "    \n",
        "    # X --> Input.\n",
        "    \n",
        "    # m-> number of training examples\n",
        "    # n-> number of features \n",
        "    m, n = X.shape\n",
        "    \n",
        "    # Normalizing all the n features of X.\n",
        "    for i in range(n):\n",
        "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
        "        \n",
        "    return X"
      ],
      "metadata": {
        "id": "4jNPc2R5Tpoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, y, bs, epochs, lr):\n",
        "    \n",
        "    # X --> Input.\n",
        "    # y --> true/target value.\n",
        "    # bs --> Batch Size.\n",
        "    # epochs --> Number of iterations.\n",
        "    # lr --> Learning rate.\n",
        "        \n",
        "    # m-> number of training examples\n",
        "    # n-> number of features \n",
        "    m, n = X.shape\n",
        "    \n",
        "    # Initializing weights and bias to zeros.\n",
        "    w = np.zeros((n,1))\n",
        "    b = 0\n",
        "    \n",
        "    # Reshaping y.\n",
        "    y = y.reshape(m,1)\n",
        "    \n",
        "    # Normalizing the inputs.\n",
        "    X = normalize(X)\n",
        "    \n",
        "    # Empty list to store losses.\n",
        "    losses = []\n",
        "    \n",
        "    # Training loop.\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((m-1)//bs + 1):\n",
        "            \n",
        "            # Defining batches. SGD.\n",
        "            start_i = i*bs\n",
        "            end_i = start_i + bs\n",
        "            xb = X[start_i:end_i]\n",
        "            yb = y[start_i:end_i]\n",
        "            \n",
        "            # Calculating hypothesis/prediction.\n",
        "            y_hat = sigmoid(np.dot(xb, w) + b)\n",
        "            \n",
        "            # Getting the gradients of loss w.r.t parameters.\n",
        "            dw, db = gradients(xb, yb, y_hat)\n",
        "            \n",
        "            # Updating the parameters.\n",
        "            w -= lr*dw\n",
        "            b -= lr*db\n",
        "        \n",
        "        # Calculating loss and appending it in the list.\n",
        "        l = loss(y, sigmoid(np.dot(X, w) + b))\n",
        "        losses.append(l)\n",
        "\n",
        "    #plt.plot(losses)\n",
        "        \n",
        "    # returning weights, bias and losses(List).\n",
        "    return w, b, losses"
      ],
      "metadata": {
        "id": "E6F8wDCjUiVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1.0/(1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "ZznseDbHSonW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b, l = train(X_train, Y_train, bs=100, epochs=1000, lr=0.01)"
      ],
      "metadata": {
        "id": "JODeeCJCTg9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X):\n",
        "    \n",
        "    # X --> Input.\n",
        "    \n",
        "    # Normalizing the inputs.\n",
        "    x = normalize(X)\n",
        "    \n",
        "    # Calculating presictions/y_hat.\n",
        "    preds = sigmoid(np.dot(x, w) + b)\n",
        "    \n",
        "    # Empty List to store predictions.\n",
        "    pred_class = []\n",
        "    # if y_hat >= 0.5 --> round up to 1\n",
        "    # if y_hat < 0.5 --> round up to 1\n",
        "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
        "    \n",
        "    return np.array(pred_class)"
      ],
      "metadata": {
        "id": "bxQwzgjGW5wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_logistic=predict(X_test)"
      ],
      "metadata": {
        "id": "1qHA4Jr-ZwXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y, y_hat):\n",
        "    accuracy = np.sum(y == y_hat) / len(y)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "zES8pgVKZ8fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(Y_test,predictions_logistic)"
      ],
      "metadata": {
        "id": "BPUSEun3awQB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db29746a-40ab-44d0-d2e9-f6b769e8d71a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9238578680203046"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.confusion_matrix(Y_test, predictions_logistic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KGAbyQffoA2",
        "outputId": "bac77364-8dbc-4738-d3cd-b85679a5bc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[91,  2],\n",
              "       [13, 91]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Neural Network\n"
      ],
      "metadata": {
        "id": "jWefolgQJAlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation= \"relu\"),\n",
        "\n",
        "  tf.keras.layers.Dense(216, activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Dense(18, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.6),\n",
        "\n",
        "  tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.SGD(learning_rate= 0.008),\n",
        "    metrics=[\n",
        "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        ")\n",
        "\n",
        "X= normalize(X_train)\n",
        "\n",
        "training= model.fit(X, Y_train, epochs= 300)"
      ],
      "metadata": {
        "id": "0zOnzG2MJdW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e70f0d9-242a-4b0a-8f88-3132d389f821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "25/25 [==============================] - 1s 3ms/step - loss: 0.6961 - accuracy: 0.5934 - precision: 0.6156 - recall: 0.4665\n",
            "Epoch 2/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.7039 - precision: 0.7273 - recall: 0.6392\n",
            "Epoch 3/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7624 - precision: 0.8000 - recall: 0.6907\n",
            "Epoch 4/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.8285 - precision: 0.8845 - recall: 0.7500\n",
            "Epoch 5/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.8234 - precision: 0.8927 - recall: 0.7294\n",
            "Epoch 6/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.8158 - precision: 0.9233 - recall: 0.6830\n",
            "Epoch 7/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.8513 - precision: 0.9329 - recall: 0.7526\n",
            "Epoch 8/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8513 - precision: 0.9414 - recall: 0.7448\n",
            "Epoch 9/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8475 - precision: 0.9268 - recall: 0.7500\n",
            "Epoch 10/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8717 - precision: 0.9388 - recall: 0.7912\n",
            "Epoch 11/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8564 - precision: 0.9310 - recall: 0.7655\n",
            "Epoch 12/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.8818 - precision: 0.9429 - recall: 0.8093\n",
            "Epoch 13/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8704 - precision: 0.9333 - recall: 0.7938\n",
            "Epoch 14/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8666 - precision: 0.9354 - recall: 0.7835\n",
            "Epoch 15/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8907 - precision: 0.9494 - recall: 0.8222\n",
            "Epoch 16/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8793 - precision: 0.9508 - recall: 0.7964\n",
            "Epoch 17/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8856 - precision: 0.9382 - recall: 0.8222\n",
            "Epoch 18/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8755 - precision: 0.9421 - recall: 0.7964\n",
            "Epoch 19/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8856 - precision: 0.9543 - recall: 0.8067\n",
            "Epoch 20/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.8793 - precision: 0.9426 - recall: 0.8041\n",
            "Epoch 21/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8920 - precision: 0.9605 - recall: 0.8144\n",
            "Epoch 22/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8958 - precision: 0.9608 - recall: 0.8222\n",
            "Epoch 23/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.9123 - precision: 0.9677 - recall: 0.8505\n",
            "Epoch 24/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9047 - precision: 0.9672 - recall: 0.8351\n",
            "Epoch 25/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8933 - precision: 0.9551 - recall: 0.8222\n",
            "Epoch 26/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.9034 - precision: 0.9432 - recall: 0.8557\n",
            "Epoch 27/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8958 - precision: 0.9581 - recall: 0.8247\n",
            "Epoch 28/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.9123 - precision: 0.9570 - recall: 0.8608\n",
            "Epoch 29/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.9009 - precision: 0.9697 - recall: 0.8247\n",
            "Epoch 30/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9072 - precision: 0.9674 - recall: 0.8402\n",
            "Epoch 31/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.9060 - precision: 0.9729 - recall: 0.8325\n",
            "Epoch 32/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.9098 - precision: 0.9516 - recall: 0.8608\n",
            "Epoch 33/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8996 - precision: 0.9725 - recall: 0.8196\n",
            "Epoch 34/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9060 - precision: 0.9511 - recall: 0.8531\n",
            "Epoch 35/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.9047 - precision: 0.9510 - recall: 0.8505\n",
            "Epoch 36/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2432 - accuracy: 0.8983 - precision: 0.9503 - recall: 0.8376\n",
            "Epoch 37/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.9098 - precision: 0.9621 - recall: 0.8505\n",
            "Epoch 38/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9123 - precision: 0.9597 - recall: 0.8582\n",
            "Epoch 39/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9149 - precision: 0.9496 - recall: 0.8737\n",
            "Epoch 40/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.8996 - precision: 0.9478 - recall: 0.8428\n",
            "Epoch 41/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9060 - precision: 0.9511 - recall: 0.8531\n",
            "Epoch 42/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2360 - accuracy: 0.9263 - precision: 0.9661 - recall: 0.8814\n",
            "Epoch 43/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9263 - precision: 0.9714 - recall: 0.8763\n",
            "Epoch 44/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9263 - precision: 0.9688 - recall: 0.8789\n",
            "Epoch 45/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9187 - precision: 0.9551 - recall: 0.8763\n",
            "Epoch 46/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9238 - precision: 0.9633 - recall: 0.8789\n",
            "Epoch 47/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9225 - precision: 0.9712 - recall: 0.8686\n",
            "Epoch 48/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9085 - precision: 0.9514 - recall: 0.8582\n",
            "Epoch 49/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9212 - precision: 0.9605 - recall: 0.8763\n",
            "Epoch 50/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9238 - precision: 0.9607 - recall: 0.8814\n",
            "Epoch 51/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2337 - accuracy: 0.9161 - precision: 0.9574 - recall: 0.8686\n",
            "Epoch 52/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9352 - precision: 0.9694 - recall: 0.8969\n",
            "Epoch 53/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2033 - accuracy: 0.9212 - precision: 0.9657 - recall: 0.8711\n",
            "Epoch 54/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9263 - precision: 0.9661 - recall: 0.8814\n",
            "Epoch 55/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2014 - accuracy: 0.9327 - precision: 0.9718 - recall: 0.8892\n",
            "Epoch 56/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9225 - precision: 0.9685 - recall: 0.8711\n",
            "Epoch 57/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9339 - precision: 0.9773 - recall: 0.8866\n",
            "Epoch 58/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9288 - precision: 0.9611 - recall: 0.8918\n",
            "Epoch 59/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9301 - precision: 0.9717 - recall: 0.8840\n",
            "Epoch 60/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9390 - precision: 0.9749 - recall: 0.8995\n",
            "Epoch 61/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9365 - precision: 0.9694 - recall: 0.8995\n",
            "Epoch 62/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9327 - precision: 0.9772 - recall: 0.8840\n",
            "Epoch 63/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9428 - precision: 0.9804 - recall: 0.9021\n",
            "Epoch 64/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.9288 - precision: 0.9586 - recall: 0.8943\n",
            "Epoch 65/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9301 - precision: 0.9612 - recall: 0.8943\n",
            "Epoch 66/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9377 - precision: 0.9775 - recall: 0.8943\n",
            "Epoch 67/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9352 - precision: 0.9668 - recall: 0.8995\n",
            "Epoch 68/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9365 - precision: 0.9721 - recall: 0.8969\n",
            "Epoch 69/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9365 - precision: 0.9592 - recall: 0.9098\n",
            "Epoch 70/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1866 - accuracy: 0.9314 - precision: 0.9639 - recall: 0.8943\n",
            "Epoch 71/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1874 - accuracy: 0.9327 - precision: 0.9564 - recall: 0.9046\n",
            "Epoch 72/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9479 - precision: 0.9780 - recall: 0.9149\n",
            "Epoch 73/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9479 - precision: 0.9728 - recall: 0.9201\n",
            "Epoch 74/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1987 - accuracy: 0.9301 - precision: 0.9587 - recall: 0.8969\n",
            "Epoch 75/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1749 - accuracy: 0.9466 - precision: 0.9727 - recall: 0.9175\n",
            "Epoch 76/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9352 - precision: 0.9668 - recall: 0.8995\n",
            "Epoch 77/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9428 - precision: 0.9751 - recall: 0.9072\n",
            "Epoch 78/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9479 - precision: 0.9728 - recall: 0.9201\n",
            "Epoch 79/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1633 - accuracy: 0.9454 - precision: 0.9675 - recall: 0.9201\n",
            "Epoch 80/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9390 - precision: 0.9645 - recall: 0.9098\n",
            "Epoch 81/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9454 - precision: 0.9778 - recall: 0.9098\n",
            "Epoch 82/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1645 - accuracy: 0.9428 - precision: 0.9725 - recall: 0.9098\n",
            "Epoch 83/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9504 - precision: 0.9807 - recall: 0.9175\n",
            "Epoch 84/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9390 - precision: 0.9696 - recall: 0.9046\n",
            "Epoch 85/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9517 - precision: 0.9808 - recall: 0.9201\n",
            "Epoch 86/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9428 - precision: 0.9751 - recall: 0.9072\n",
            "Epoch 87/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9466 - precision: 0.9832 - recall: 0.9072\n",
            "Epoch 88/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9327 - precision: 0.9564 - recall: 0.9046\n",
            "Epoch 89/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9517 - precision: 0.9755 - recall: 0.9253\n",
            "Epoch 90/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9466 - precision: 0.9806 - recall: 0.9098\n",
            "Epoch 91/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9466 - precision: 0.9806 - recall: 0.9098\n",
            "Epoch 92/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9492 - precision: 0.9754 - recall: 0.9201\n",
            "Epoch 93/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9543 - precision: 0.9862 - recall: 0.9201\n",
            "Epoch 94/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9517 - precision: 0.9888 - recall: 0.9124\n",
            "Epoch 95/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9416 - precision: 0.9672 - recall: 0.9124\n",
            "Epoch 96/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9543 - precision: 0.9862 - recall: 0.9201\n",
            "Epoch 97/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9416 - precision: 0.9672 - recall: 0.9124\n",
            "Epoch 98/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9466 - precision: 0.9779 - recall: 0.9124\n",
            "Epoch 99/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9492 - precision: 0.9703 - recall: 0.9253\n",
            "Epoch 100/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9530 - precision: 0.9808 - recall: 0.9227\n",
            "Epoch 101/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9504 - precision: 0.9704 - recall: 0.9278\n",
            "Epoch 102/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9403 - precision: 0.9697 - recall: 0.9072\n",
            "Epoch 103/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9543 - precision: 0.9706 - recall: 0.9356\n",
            "Epoch 104/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9428 - precision: 0.9777 - recall: 0.9046\n",
            "Epoch 105/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1613 - accuracy: 0.9492 - precision: 0.9780 - recall: 0.9175\n",
            "Epoch 106/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9454 - precision: 0.9778 - recall: 0.9098\n",
            "Epoch 107/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9454 - precision: 0.9778 - recall: 0.9098\n",
            "Epoch 108/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9568 - precision: 0.9836 - recall: 0.9278\n",
            "Epoch 109/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1444 - accuracy: 0.9530 - precision: 0.9782 - recall: 0.9253\n",
            "Epoch 110/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9517 - precision: 0.9730 - recall: 0.9278\n",
            "Epoch 111/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9555 - precision: 0.9809 - recall: 0.9278\n",
            "Epoch 112/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9517 - precision: 0.9861 - recall: 0.9149\n",
            "Epoch 113/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9403 - precision: 0.9723 - recall: 0.9046\n",
            "Epoch 114/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9479 - precision: 0.9780 - recall: 0.9149\n",
            "Epoch 115/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9555 - precision: 0.9783 - recall: 0.9304\n",
            "Epoch 116/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9568 - precision: 0.9810 - recall: 0.9304\n",
            "Epoch 117/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9568 - precision: 0.9836 - recall: 0.9278\n",
            "Epoch 118/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9543 - precision: 0.9706 - recall: 0.9356\n",
            "Epoch 119/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9517 - precision: 0.9861 - recall: 0.9149\n",
            "Epoch 120/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9619 - precision: 0.9891 - recall: 0.9330\n",
            "Epoch 121/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9492 - precision: 0.9728 - recall: 0.9227\n",
            "Epoch 122/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9606 - precision: 0.9864 - recall: 0.9330\n",
            "Epoch 123/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9619 - precision: 0.9838 - recall: 0.9381\n",
            "Epoch 124/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9466 - precision: 0.9860 - recall: 0.9046\n",
            "Epoch 125/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9454 - precision: 0.9726 - recall: 0.9149\n",
            "Epoch 126/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9530 - precision: 0.9808 - recall: 0.9227\n",
            "Epoch 127/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9619 - precision: 0.9864 - recall: 0.9356\n",
            "Epoch 128/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9606 - precision: 0.9811 - recall: 0.9381\n",
            "Epoch 129/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9632 - precision: 0.9891 - recall: 0.9356\n",
            "Epoch 130/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9568 - precision: 0.9758 - recall: 0.9356\n",
            "Epoch 131/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9454 - precision: 0.9778 - recall: 0.9098\n",
            "Epoch 132/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9568 - precision: 0.9836 - recall: 0.9278\n",
            "Epoch 133/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9657 - precision: 0.9865 - recall: 0.9433\n",
            "Epoch 134/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9619 - precision: 0.9864 - recall: 0.9356\n",
            "Epoch 135/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9606 - precision: 0.9837 - recall: 0.9356\n",
            "Epoch 136/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9632 - precision: 0.9812 - recall: 0.9433\n",
            "Epoch 137/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9543 - precision: 0.9783 - recall: 0.9278\n",
            "Epoch 138/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1357 - accuracy: 0.9581 - precision: 0.9837 - recall: 0.9304\n",
            "Epoch 139/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9568 - precision: 0.9863 - recall: 0.9253\n",
            "Epoch 140/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9644 - precision: 0.9865 - recall: 0.9407\n",
            "Epoch 141/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9593 - precision: 0.9890 - recall: 0.9278\n",
            "Epoch 142/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9593 - precision: 0.9811 - recall: 0.9356\n",
            "Epoch 143/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9632 - precision: 0.9918 - recall: 0.9330\n",
            "Epoch 144/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1086 - accuracy: 0.9657 - precision: 0.9918 - recall: 0.9381\n",
            "Epoch 145/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9555 - precision: 0.9783 - recall: 0.9304\n",
            "Epoch 146/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9593 - precision: 0.9944 - recall: 0.9227\n",
            "Epoch 147/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9632 - precision: 0.9891 - recall: 0.9356\n",
            "Epoch 148/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9606 - precision: 0.9890 - recall: 0.9304\n",
            "Epoch 149/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9543 - precision: 0.9862 - recall: 0.9201\n",
            "Epoch 150/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9504 - precision: 0.9807 - recall: 0.9175\n",
            "Epoch 151/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1300 - accuracy: 0.9632 - precision: 0.9838 - recall: 0.9407\n",
            "Epoch 152/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9632 - precision: 0.9891 - recall: 0.9356\n",
            "Epoch 153/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1363 - accuracy: 0.9695 - precision: 0.9892 - recall: 0.9485\n",
            "Epoch 154/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1338 - accuracy: 0.9581 - precision: 0.9708 - recall: 0.9433\n",
            "Epoch 155/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9720 - precision: 0.9893 - recall: 0.9536\n",
            "Epoch 156/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1273 - accuracy: 0.9581 - precision: 0.9890 - recall: 0.9253\n",
            "Epoch 157/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9606 - precision: 0.9890 - recall: 0.9304\n",
            "Epoch 158/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9632 - precision: 0.9864 - recall: 0.9381\n",
            "Epoch 159/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9606 - precision: 0.9864 - recall: 0.9330\n",
            "Epoch 160/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1283 - accuracy: 0.9670 - precision: 0.9892 - recall: 0.9433\n",
            "Epoch 161/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9593 - precision: 0.9944 - recall: 0.9227\n",
            "Epoch 162/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1316 - accuracy: 0.9632 - precision: 0.9838 - recall: 0.9407\n",
            "Epoch 163/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9644 - precision: 0.9891 - recall: 0.9381\n",
            "Epoch 164/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9682 - precision: 0.9946 - recall: 0.9407\n",
            "Epoch 165/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9657 - precision: 0.9865 - recall: 0.9433\n",
            "Epoch 166/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9593 - precision: 0.9863 - recall: 0.9304\n",
            "Epoch 167/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9695 - precision: 0.9919 - recall: 0.9459\n",
            "Epoch 168/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9657 - precision: 0.9865 - recall: 0.9433\n",
            "Epoch 169/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9657 - precision: 0.9865 - recall: 0.9433\n",
            "Epoch 170/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9632 - precision: 0.9945 - recall: 0.9304\n",
            "Epoch 171/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9619 - precision: 0.9812 - recall: 0.9407\n",
            "Epoch 172/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9682 - precision: 0.9946 - recall: 0.9407\n",
            "Epoch 173/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 0.9644 - precision: 0.9865 - recall: 0.9407\n",
            "Epoch 174/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9606 - precision: 0.9837 - recall: 0.9356\n",
            "Epoch 175/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.9682 - precision: 0.9814 - recall: 0.9536\n",
            "Epoch 176/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9644 - precision: 0.9945 - recall: 0.9330\n",
            "Epoch 177/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1190 - accuracy: 0.9632 - precision: 0.9864 - recall: 0.9381\n",
            "Epoch 178/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9619 - precision: 0.9891 - recall: 0.9330\n",
            "Epoch 179/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9657 - precision: 0.9763 - recall: 0.9536\n",
            "Epoch 180/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9670 - precision: 0.9918 - recall: 0.9407\n",
            "Epoch 181/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9619 - precision: 0.9891 - recall: 0.9330\n",
            "Epoch 182/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1157 - accuracy: 0.9644 - precision: 0.9839 - recall: 0.9433\n",
            "Epoch 183/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9657 - precision: 0.9865 - recall: 0.9433\n",
            "Epoch 184/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9657 - precision: 0.9892 - recall: 0.9407\n",
            "Epoch 185/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9708 - precision: 0.9973 - recall: 0.9433\n",
            "Epoch 186/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9568 - precision: 0.9836 - recall: 0.9278\n",
            "Epoch 187/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9581 - precision: 0.9890 - recall: 0.9253\n",
            "Epoch 188/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9670 - precision: 0.9892 - recall: 0.9433\n",
            "Epoch 189/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9657 - precision: 0.9918 - recall: 0.9381\n",
            "Epoch 190/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9708 - precision: 0.9919 - recall: 0.9485\n",
            "Epoch 191/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9555 - precision: 0.9889 - recall: 0.9201\n",
            "Epoch 192/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9632 - precision: 0.9864 - recall: 0.9381\n",
            "Epoch 193/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9657 - precision: 0.9918 - recall: 0.9381\n",
            "Epoch 194/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9632 - precision: 0.9838 - recall: 0.9407\n",
            "Epoch 195/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9682 - precision: 0.9892 - recall: 0.9459\n",
            "Epoch 196/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9670 - precision: 0.9918 - recall: 0.9407\n",
            "Epoch 197/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 198/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9619 - precision: 0.9864 - recall: 0.9356\n",
            "Epoch 199/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9619 - precision: 0.9786 - recall: 0.9433\n",
            "Epoch 200/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9720 - precision: 0.9973 - recall: 0.9459\n",
            "Epoch 201/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9657 - precision: 0.9892 - recall: 0.9407\n",
            "Epoch 202/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n",
            "Epoch 203/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9733 - precision: 0.9893 - recall: 0.9562\n",
            "Epoch 204/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9670 - precision: 0.9945 - recall: 0.9381\n",
            "Epoch 205/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9670 - precision: 0.9866 - recall: 0.9459\n",
            "Epoch 206/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9543 - precision: 0.9862 - recall: 0.9201\n",
            "Epoch 207/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9695 - precision: 0.9919 - recall: 0.9459\n",
            "Epoch 208/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9733 - precision: 0.9893 - recall: 0.9562\n",
            "Epoch 209/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n",
            "Epoch 210/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9670 - precision: 0.9840 - recall: 0.9485\n",
            "Epoch 211/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9670 - precision: 0.9814 - recall: 0.9510\n",
            "Epoch 212/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9695 - precision: 0.9892 - recall: 0.9485\n",
            "Epoch 213/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9759 - precision: 0.9920 - recall: 0.9588\n",
            "Epoch 214/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 215/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9733 - precision: 0.9946 - recall: 0.9510\n",
            "Epoch 216/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 217/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9708 - precision: 0.9973 - recall: 0.9433\n",
            "Epoch 218/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9657 - precision: 0.9918 - recall: 0.9381\n",
            "Epoch 219/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9682 - precision: 0.9919 - recall: 0.9433\n",
            "Epoch 220/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9708 - precision: 0.9946 - recall: 0.9459\n",
            "Epoch 221/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9581 - precision: 0.9890 - recall: 0.9253\n",
            "Epoch 222/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9746 - precision: 0.9894 - recall: 0.9588\n",
            "Epoch 223/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9657 - precision: 0.9892 - recall: 0.9407\n",
            "Epoch 224/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9708 - precision: 0.9893 - recall: 0.9510\n",
            "Epoch 225/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9708 - precision: 0.9919 - recall: 0.9485\n",
            "Epoch 226/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9720 - precision: 0.9973 - recall: 0.9459\n",
            "Epoch 227/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n",
            "Epoch 228/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 229/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9733 - precision: 0.9893 - recall: 0.9562\n",
            "Epoch 230/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n",
            "Epoch 231/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9682 - precision: 0.9866 - recall: 0.9485\n",
            "Epoch 232/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1112 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 233/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9708 - precision: 0.9946 - recall: 0.9459\n",
            "Epoch 234/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9632 - precision: 0.9918 - recall: 0.9330\n",
            "Epoch 235/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 236/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0913 - accuracy: 0.9784 - precision: 0.9920 - recall: 0.9639\n",
            "Epoch 237/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9809 - precision: 0.9947 - recall: 0.9665\n",
            "Epoch 238/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 239/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9746 - precision: 0.9973 - recall: 0.9510\n",
            "Epoch 240/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9771 - precision: 0.9947 - recall: 0.9588\n",
            "Epoch 241/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 242/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 243/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 244/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9682 - precision: 0.9919 - recall: 0.9433\n",
            "Epoch 245/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9632 - precision: 0.9864 - recall: 0.9381\n",
            "Epoch 246/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9746 - precision: 0.9894 - recall: 0.9588\n",
            "Epoch 247/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9682 - precision: 0.9946 - recall: 0.9407\n",
            "Epoch 248/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9682 - precision: 0.9946 - recall: 0.9407\n",
            "Epoch 249/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9720 - precision: 0.9919 - recall: 0.9510\n",
            "Epoch 250/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9746 - precision: 0.9973 - recall: 0.9510\n",
            "Epoch 251/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9720 - precision: 0.9893 - recall: 0.9536\n",
            "Epoch 252/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9708 - precision: 0.9973 - recall: 0.9433\n",
            "Epoch 253/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9733 - precision: 0.9973 - recall: 0.9485\n",
            "Epoch 254/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1019 - accuracy: 0.9720 - precision: 0.9973 - recall: 0.9459\n",
            "Epoch 255/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 256/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n",
            "Epoch 257/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9720 - precision: 0.9946 - recall: 0.9485\n",
            "Epoch 258/300\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9784 - precision: 0.9947 - recall: 0.9613\n",
            "Epoch 259/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 260/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9720 - precision: 0.9973 - recall: 0.9459\n",
            "Epoch 261/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9759 - precision: 0.9973 - recall: 0.9536\n",
            "Epoch 262/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9720 - precision: 0.9973 - recall: 0.9459\n",
            "Epoch 263/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9759 - precision: 0.9973 - recall: 0.9536\n",
            "Epoch 264/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9708 - precision: 0.9893 - recall: 0.9510\n",
            "Epoch 265/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 266/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9784 - precision: 0.9973 - recall: 0.9588\n",
            "Epoch 267/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 268/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 269/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9771 - precision: 0.9947 - recall: 0.9588\n",
            "Epoch 270/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9784 - precision: 0.9973 - recall: 0.9588\n",
            "Epoch 271/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 272/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9746 - precision: 0.9920 - recall: 0.9562\n",
            "Epoch 273/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 274/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9784 - precision: 0.9973 - recall: 0.9588\n",
            "Epoch 275/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9657 - precision: 0.9918 - recall: 0.9381\n",
            "Epoch 276/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1002 - accuracy: 0.9720 - precision: 0.9893 - recall: 0.9536\n",
            "Epoch 277/300\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9733 - precision: 0.9920 - recall: 0.9536\n",
            "Epoch 278/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9720 - precision: 0.9919 - recall: 0.9510\n",
            "Epoch 279/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9733 - precision: 0.9920 - recall: 0.9536\n",
            "Epoch 280/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9759 - precision: 0.9920 - recall: 0.9588\n",
            "Epoch 281/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9797 - precision: 0.9973 - recall: 0.9613\n",
            "Epoch 282/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9759 - precision: 0.9973 - recall: 0.9536\n",
            "Epoch 283/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 284/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 285/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9720 - precision: 0.9919 - recall: 0.9510\n",
            "Epoch 286/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9746 - precision: 0.9946 - recall: 0.9536\n",
            "Epoch 287/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9720 - precision: 0.9919 - recall: 0.9510\n",
            "Epoch 288/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9835 - precision: 0.9973 - recall: 0.9691\n",
            "Epoch 289/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9759 - precision: 0.9946 - recall: 0.9562\n",
            "Epoch 290/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0797 - accuracy: 0.9771 - precision: 0.9973 - recall: 0.9562\n",
            "Epoch 291/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9733 - precision: 0.9946 - recall: 0.9510\n",
            "Epoch 292/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0817 - accuracy: 0.9759 - precision: 0.9973 - recall: 0.9536\n",
            "Epoch 293/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9759 - precision: 0.9920 - recall: 0.9588\n",
            "Epoch 294/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0831 - accuracy: 0.9771 - precision: 0.9947 - recall: 0.9588\n",
            "Epoch 295/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9809 - precision: 0.9973 - recall: 0.9639\n",
            "Epoch 296/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9708 - precision: 0.9919 - recall: 0.9485\n",
            "Epoch 297/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9771 - precision: 0.9894 - recall: 0.9639\n",
            "Epoch 298/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9797 - precision: 0.9973 - recall: 0.9613\n",
            "Epoch 299/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9746 - precision: 0.9973 - recall: 0.9510\n",
            "Epoch 300/300\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9695 - precision: 0.9946 - recall: 0.9433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(\n",
        "    np.arange(1, 301), \n",
        "    training.history['loss'], label='Value of loss function'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "EB8hLf3FbkmE",
        "outputId": "684f7b86-5493-4469-b914-f9eb7fd6bb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8128c1b290>]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(normalize(X_test), Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPV4Sg97esQ7",
        "outputId": "04b70cbb-e898-45a8-ac13-2c68605cd59b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9492 - precision: 0.9700 - recall: 0.9327\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.18323421478271484,\n",
              " 0.9492385983467102,\n",
              " 0.9700000286102295,\n",
              " 0.932692289352417]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_nn= model.predict(normalize(X_test))\n",
        "predictions_nn= [1 if i>=0.5 else 0 for i in list(predictions_nn)]"
      ],
      "metadata": {
        "id": "ENJkIAy8dBa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.confusion_matrix(Y_test, predictions_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbEDNe9keYGW",
        "outputId": "7681616d-01e9-4bb0-e26d-85fbaaafb4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[90,  3],\n",
              "       [ 7, 97]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SVM with linear kernel"
      ],
      "metadata": {
        "id": "Kv0TeZOAoH_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rbf_svc_linear = svm.SVC(kernel='linear')\n",
        "rbf_svc_linear.fit(X, Y_train)\n",
        "\n",
        "predictions_svm_linear= rbf_svc.predict(normalize(X_test))\n",
        "\n",
        "tf.math.confusion_matrix(Y_test, predictions_svm_linear)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYdX3MmGoLA3",
        "outputId": "1a40c0ea-4f78-4e29-c0d5-45c252c42fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[92,  1],\n",
              "       [11, 93]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SVM with RBF kernel"
      ],
      "metadata": {
        "id": "9i7H5Q08gK8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rbf_svc_rbf = svm.SVC(kernel='rbf')\n",
        "rbf_svc_rbf.fit(X, Y_train)\n",
        "\n",
        "predictions_svm_rbf= rbf_svc.predict(normalize(X_test))\n",
        "\n",
        "tf.math.confusion_matrix(Y_test, predictions_svm_rbf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L48lmC9tgJki",
        "outputId": "28f71bac-21ae-47c0-dc61-a2912cde64bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[92,  1],\n",
              "       [11, 93]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8ZOMbV5bkdGj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}